defaults:
  - base_video

# Raw mp4 root (scanned recursively by datasets/video/memory_world.py)
save_dir: /Users/kaijinchen/Documents/GitHub/Memory-World/dynamic_memory
# Caption-based sample list (aligned with vae_process_dataset.py)
captions_path: ${dataset.save_dir}/captions.txt
captions_root: ${dataset.save_dir}
split_seed: 42
train_ratio: 0.9
metadata_num_workers: 16

# Train with local temporal windows for memory/computation efficiency.
max_frames: 32
context_length: 16
frame_skip: 1

# Run long-horizon validation/generation on the full 77 + 77 task.
n_frames: 154
filter_min_len: 1

resolution: 256
external_cond_dim: 16
external_cond_stack: false
external_cond_processing: identity

# Start from normalized RGB defaults; replace with measured dataset stats later.
data_mean: [[[0.5]], [[0.5]], [[0.5]]]
data_std: [[[0.5]], [[0.5]], [[0.5]]]
